# Adam

## 프로젝트 소개

Img2Story는 이미지를 입력으로 받아 그에 어울리는 스토리를 만들어냅니다.

<p align="center"><img src="https://user-images.githubusercontent.com/69384652/170828601-c7c804bc-2c48-4b39-af9f-924db5a0aa7b.png" height="250px" width="650px"></p>

## Step

### 1. paper review
### 2. MSCOCO dataset -> dataload
### 3. Model ( Image captioning part)
### 4. Train

## Papers

### Image Captioning
[Show and Tell : A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555)

[Show, Attend, and Tell : Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044)


## References

### Image Captioning
[Implementation of Show and Tell](https://github.com/nalbert9/Image-Captioning)

[CLIP: Connecting Text and Images](https://openai.com/blog/clip/)

### Story Generator
[Generating Stories about Images](https://medium.com/@samim/generating-stories-about-images-d163ba41e4ed)

[Microsoft AI Lab : Pix2Story](https://azure.microsoft.com/ko-kr/blog/pix2story-neural-storyteller-which-creates-machine-generated-story-in-several-literature-genre/)

### Image-to-Story, Metrics
[딥인코더-디코더 기반의 인공지능 포토 스토리텔러 ](https://koreascience.kr/article/CFKO201924664108409.pdf)

[Every picture tells a story: Image-grounded controllable stylistic story generation](https://arxiv.org/abs/2209.01638)
